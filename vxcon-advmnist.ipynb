{
 "metadata": {
  "name": "",
  "signature": "sha256:91a52283af6f19832a7783ec6658cbd29444ff39522de7fe23cc0bc888a36d04"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import absolute_import\n",
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "from __future__ import unicode_literals\n",
      "\n",
      "import keras\n",
      "from keras import backend\n",
      "\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.platform import app\n",
      "from tensorflow.python.platform import flags\n",
      "\n",
      "from cleverhans.utils_mnist import data_mnist\n",
      "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
      "from cleverhans.attacks import fgsm\n",
      "from cleverhans.utils import cnn_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FLAGS = flags.FLAGS\n",
      "\n",
      "flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
      "flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
      "flags.DEFINE_float('learning_rate', 0.1, 'Learning rate for training')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set TF random seed to improve reproducibility\n",
      "tf.set_random_seed(1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create TF session and set as Keras backend session\n",
      "sess = tf.Session()\n",
      "keras.backend.set_session(sess)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, Y_train, X_test, Y_test = data_mnist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X_train shape: (60000, 28, 28, 1)\n",
        "60000 train samples\n",
        "10000 test samples\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert Y_train.shape[1] == 10.\n",
      "label_smooth = .1\n",
      "Y_train = Y_train.clip(label_smooth / 9., 1. - label_smooth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define input TF placeholder\n",
      "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
      "y = tf.placeholder(tf.float32, shape=(None, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define TF model graph\n",
      "model = cnn_model()\n",
      "predictions = model(x)\n",
      "print(\"Defined TensorFlow model graph.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Defined TensorFlow model graph.\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate():\n",
      "    # Evaluate the accuracy of the MNIST model on legitimate test examples\n",
      "    eval_params = {'batch_size': FLAGS.batch_size}\n",
      "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test,\n",
      "                          args=eval_params)\n",
      "    assert X_test.shape[0] == 10000, X_test.shape\n",
      "    print('Test accuracy on legitimate test examples: ' + str(accuracy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train an MNIST model\n",
      "train_params = {\n",
      "    'nb_epochs': FLAGS.nb_epochs,\n",
      "    'batch_size': FLAGS.batch_size,\n",
      "    'learning_rate': FLAGS.learning_rate\n",
      "}\n",
      "model_train(sess, x, y, predictions, X_train, Y_train,\n",
      "            evaluate=evaluate, args=train_params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 0\n",
        "\tEpoch took 225.791234016 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9136"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1\n",
        "\tEpoch took 233.609632969 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9365"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2\n",
        "\tEpoch took 205.233453989 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9487"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3\n",
        "\tEpoch took 177.932695866 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9563"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4\n",
        "\tEpoch took 190.463292122 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5\n",
        "\tEpoch took 176.641102076 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Completed model training.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Craft adversarial examples using Fast Gradient Sign Method (FGSM)\n",
      "adv_x = fgsm(x, predictions, eps=0.3)\n",
      "eval_params = {'batch_size': FLAGS.batch_size}\n",
      "X_test_adv, = batch_eval(sess, [x], [adv_x], [X_test], args=eval_params)\n",
      "assert X_test_adv.shape[0] == 10000, X_test_adv.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate the accuracy of the MNIST model on adversarial examples\n",
      "accuracy = model_eval(sess, x, y, predictions, X_test_adv, Y_test,\n",
      "                      args=eval_params)\n",
      "print('Test accuracy on adversarial examples: ' + str(accuracy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test accuracy on adversarial examples: 0.0202\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Repeating the process, using adversarial training\")\n",
      "# Redefine TF model graph\n",
      "model_2 = cnn_model()\n",
      "predictions_2 = model_2(x)\n",
      "adv_x_2 = fgsm(x, predictions_2, eps=0.3)\n",
      "predictions_2_adv = model_2(adv_x_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Repeating the process, using adversarial training\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_2():\n",
      "        # Evaluate the accuracy of the adversarialy trained MNIST model on\n",
      "        # legitimate test examples\n",
      "        eval_params = {'batch_size': FLAGS.batch_size}\n",
      "        accuracy = model_eval(sess, x, y, predictions_2, X_test, Y_test,\n",
      "                              args=eval_params)\n",
      "        print('Test accuracy on legitimate test examples: ' + str(accuracy))\n",
      "\n",
      "        # Evaluate the accuracy of the adversarially trained MNIST model on\n",
      "        # adversarial examples\n",
      "        accuracy_adv = model_eval(sess, x, y, predictions_2_adv, X_test,\n",
      "                                  Y_test, args=eval_params)\n",
      "        print('Test accuracy on adversarial examples: ' + str(accuracy_adv))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Perform adversarial training\n",
      "model_train(sess, x, y, predictions_2, X_train, Y_train,\n",
      "            predictions_adv=predictions_2_adv, evaluate=evaluate_2,\n",
      "            args=train_params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 0\n",
        "\tEpoch took 1972.61916709 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.8967"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.1825"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1\n",
        "\tEpoch took 461.493721962 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.939"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.2752"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2\n",
        "\tEpoch took 424.501492977 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9525"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.3431"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3\n",
        "\tEpoch took 465.872581959 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.3887"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4\n",
        "\tEpoch took 413.785032988 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9627"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.4398"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5\n",
        "\tEpoch took 421.769898176 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on legitimate test examples: 0.9658"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy on adversarial examples: 0.4617"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Completed model training.\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}